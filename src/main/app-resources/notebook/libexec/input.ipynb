{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-ext-02-03-07 - NDVI anomalies of growing season per parcel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI anomalies of growing season per parcel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'NDVI anomalies of growing season per parcel'),\n",
    "                ('abstract', 'NDVI anomalies of growing season per parcel'),\n",
    "                ('id', 'ewf-ext-02-03-07')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON ((-8.864205 38.88616500000001, -8.864205 38.986165, -8.964205000000002 38.986165, -8.964205000000002 38.88616500000001, -8.864205 38.88616500000001))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'P001'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexAndApiKeys = dict([('id', 'indexAndApiKeys'),\n",
    "                        ('value', 'better-ext-02-03-02,AKCp5dKscBjS2xuYhwSmqgvk2GGQ1rpxgLH2NqT9sD915j16AXj8Vy1S8Jwr5cFPX3EvHQxAT,better-ext-02-03-06,AKCp5dKscBjYU72HVTdPAAJJxVZjxTvyRtnF6eEM9TZvLifvFCDttrBDDKwPVbXoQPsb7JGf8'),\n",
    "                        ('title', 'index,apikey pairs'),\n",
    "                        ('abstract', 'index,apikey pairs'),\n",
    "                        ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the NDVI stats' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2015, 2015\n",
    "#difNdvi\n",
    "#input_identifiers = ('LE07_ndviStats_P001_2015005_2015365.xlsx', 'LTA_LE07_ndviStats_P001_2015_2015.xlsx')\n",
    "input_identifiers = ('E58456AA001B0A163CE829A579EFE1F4D10D2580','D4127BC272572368F1A819BCBCC312DB734FFE19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#input_references = tuple(['https://catalog.terradue.com/modis/search?format=atom&uid={0}'.format(pid) for pid in input_identifiers])\n",
    "input_references = ('https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=E58456AA001B0A163CE829A579EFE1F4D10D2580','https://catalog.terradue.com/better-ext-02-03-06/search?format=atom&uid=D4127BC272572368F1A819BCBCC312DB734FFE19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aux folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pdb\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata from catalog\n",
    "def get_input_metadata (input_refs, apikeys):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        for index in apikeys:\n",
    "            if index in product_ref:\n",
    "                cat_index = index\n",
    "                cat_apikey = apikeys[index]\n",
    "        \n",
    "        # since the search is by identifier\n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,startdate,enddate,wkt,title',creds='{}:{}'.format(cat_index,cat_apikey))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata\n",
    "\n",
    "\n",
    "def get_formatted_date(datetime_str):\n",
    "    date = datetime.datetime.strftime(datetime_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    " \n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "\n",
    "    first_date_str = get_formatted_date(first_date)\n",
    "    last_date_str = get_formatted_date(last_date)\n",
    "\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date_str, last_date_str))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data (agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better-ext-02-03-02\n",
      "better-ext-02-03-06\n"
     ]
    }
   ],
   "source": [
    "# organize indexes and apikeys in a python dictionary\n",
    "indexAndApiKeys_splited = indexAndApiKeys['value'].split(',')\n",
    "apikeys = {}\n",
    "for idx,ele in enumerate(indexAndApiKeys_splited):\n",
    "    \n",
    "    if (idx % 2 == 0):\n",
    "        print(ele)\n",
    "        apikeys[ele] = indexAndApiKeys_splited[idx+1]\n",
    "        \n",
    "\n",
    "# get input data from catalog\n",
    "input_metadata = get_input_metadata (input_references, apikeys)\n",
    "\n",
    "\n",
    "\n",
    "input_metadata_LTA = input_metadata[input_metadata['title'].str.find('LTA') != -1]\n",
    "input_metadata_Agg = input_metadata[input_metadata['title'].str.find('LTA') == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file paths\n",
    "filepath_agg = os.path.join(data_path, input_metadata_Agg['enclosure'].iloc[0].split('/')[-1])\n",
    "filepath_LTA = os.path.join(data_path, input_metadata_LTA['enclosure'].iloc[0].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data into a python dictionary\n",
    "# key -> variable name\n",
    "# content -> list of pandas dataframe, one per season (TS)\n",
    "data_agg = {}\n",
    "\n",
    "var_names = ['start_growing_season', 'end_growing_season', 'dif_ndvi', 'cumulative_ndvi', 'peak_ndvi']\n",
    "\n",
    "f = filepath_agg\n",
    "for var in var_names:\n",
    "\n",
    "    df = pd.read_excel (f, sheet_name=var)\n",
    "    #print (df)\n",
    "    \n",
    "    # remove useless column\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    data_agg[var] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data (LTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into a python dictionary\n",
    "# key -> variable name\n",
    "# content -> list of pandas dataframe, one per season (TS)\n",
    "data_LTA = {}\n",
    "\n",
    "var_names = ['start_growing_season', 'end_growing_season', 'dif_ndvi', 'cumulative_ndvi', 'peak_ndvi']\n",
    "\n",
    "f = filepath_LTA\n",
    "for var in var_names:\n",
    "\n",
    "    df = pd.read_excel (f, sheet_name=var)\n",
    "    #print (df)\n",
    "    \n",
    "    # remove useless column\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    data_LTA[var] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Amomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new python dictionary to store LTAs\n",
    "anom_data = {}\n",
    "\n",
    "anom_data = data_agg.copy()\n",
    "\n",
    "# to each var computes mean\n",
    "for var in var_names:\n",
    "\n",
    "    #anom_data[var][var] = data_LTA[var][var].div(data_agg[var][var])\n",
    "    anom_data[var][var] = data_agg[var][var].div(data_LTA[var][var])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly_LE07_ndviStats_P001_2016005_2016365_LTA_2015_2017.xlsx\n"
     ]
    }
   ],
   "source": [
    "name_parts = filepath_agg.split('/')[-1].split('.')[0].split('_')\n",
    "\n",
    "#Anomaly_LE07_difNdvi_P001_2015005_2015020_LTA_2015-2015\n",
    "\n",
    "mission = name_parts[0]\n",
    "prod = name_parts[1]\n",
    "aoi_name = name_parts[2]\n",
    "start_date = name_parts[3]\n",
    "end_date = name_parts[4]\n",
    "\n",
    "name_parts = filepath_LTA.split('/')[-1].split('.')[0].split('_')\n",
    "\n",
    "start_year_LTA = name_parts[4]\n",
    "end_year_LTA = name_parts[5]\n",
    "\n",
    "#start_date = str(anom_data['start_growing_season']['start_date'][0].year)\n",
    "#end_date = str(anom_data['start_growing_season']['end_date'][0].year)\n",
    "\n",
    "excel_output_name = '_'.join(['Anomaly', mission, prod, aoi_name, start_date, end_date, 'LTA', start_year_LTA, end_year_LTA]) + '.xlsx'\n",
    "    \n",
    "excel_output_name = os.path.join(output_folder, excel_output_name)\n",
    "\n",
    "print(excel_output_name)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(excel_output_name) as writer:  # doctest: +SKIP\n",
    "    \n",
    "    for key in anom_data:\n",
    "    \n",
    "        anom_data[key].to_excel(writer, sheet_name=key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write properties file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_properties_file(excel_output_name, input_metadata_Agg['startdate'].iloc[0], input_metadata_Agg['enddate'].iloc[0], regionOfInterest['value'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
